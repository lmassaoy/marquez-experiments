{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a205875",
   "metadata": {},
   "source": [
    "Initializing Spark Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4abac6f3-149e-4fb8-b00f-4a416f062d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "\n",
    "# jars = [\"/home/jovyan/openlineage/libs/openlineage-spark-1.5.0.jar\"]\n",
    "marquez_url = \"http://k8s-marquez-marquez-1f83396143-232926722.us-east-1.elb.amazonaws.com/api/v1\"\n",
    "marquez_namespace = 'notebook_experiments'\n",
    "\n",
    "\n",
    "spark = (SparkSession.builder.master('local')\n",
    "            .appName('complex_data_types_experiments')\n",
    "            # .config('spark.jars', \",\".join(jars))\n",
    "            # .config('spark.jars.packages', 'io.openlineage:openlineage-spark:1.5.0')\n",
    "            # .config('spark.extraListeners', 'io.openlineage.spark.agent.OpenLineageSparkListener')\n",
    "            # .config('spark.openlineage.appName', 'complex_data_type') # overwriting Spark app name in events \n",
    "            \n",
    "            # # using HTTP transport, sending events directly to Marquez endpoint\n",
    "            # .config('spark.openlineage.transport.type', 'http')\n",
    "            # .config('spark.openlineage.transport.url', marquez_url)\n",
    "            \n",
    "            # # evolve to capture an env var\n",
    "            # .config('spark.openlineage.namespace', marquez_namespace)\n",
    "            .getOrCreate())\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"INFO\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965ea4d7",
   "metadata": {},
   "source": [
    "Generic DataFrame for initial experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4ea4deb7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+-----------------------+---+---------+\n",
      "|a  |b        |c                      |d  |e        |\n",
      "+---+---------+-----------------------+---+---------+\n",
      "|1  |[1, 2, 3]|{name -> null, id -> 1}|1.5|blablabla|\n",
      "|2  |[3, 4, 5]|{name -> null, id -> 2}|1.5|blablabla|\n",
      "|3  |[6, 7, 8]|{name -> null, id -> 3}|1.5|blablabla|\n",
      "+---+---------+-----------------------+---+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "generic_df = spark.createDataFrame([\n",
    "    {'a': 1, 'b': [1,2,3], 'c': {'id': 1, 'name': {'first': 'luis', 'last': 'yamada'}}, 'd': 1.500, 'e': 'blablabla'},\n",
    "    {'a': 2, 'b': [3,4,5], 'c': {'id': 2, 'name': {'first': 'marcos', 'last': 'andrade'}}, 'd': 1.500, 'e': 'blablabla'},\n",
    "    {'a': 3, 'b': [6,7,8], 'c': {'id': 3, 'name': {'first': 'walace', 'last': 'morais'}}, 'd': 1.500, 'e': 'blablabla'}\n",
    "])\n",
    "generic_df.show(3,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "41bfdcab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- a: long (nullable = true)\n",
      " |-- b: array (nullable = true)\n",
      " |    |-- element: long (containsNull = true)\n",
      " |-- c: map (nullable = true)\n",
      " |    |-- key: string\n",
      " |    |-- value: long (valueContainsNull = true)\n",
      " |-- d: double (nullable = true)\n",
      " |-- e: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "generic_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "94d70a0a-8a08-4448-9a8e-5d0173098c79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "BIGINT\n",
      "\n",
      "b\n",
      "ARRAY<BIGINT>\n",
      "\n",
      "c\n",
      "MAP<STRING,BIGINT>\n",
      "\n",
      "d\n",
      "DOUBLE\n",
      "\n",
      "e\n",
      "STRING\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for column in generic_df.schema:\n",
    "    # print(column)\n",
    "    print(column.name)\n",
    "    # if column.dataType.simpleString()[:3] == \"map\":\n",
    "    #     print(\"MAP\")\n",
    "    # else:\n",
    "    print(column.dataType.simpleString().upper())\n",
    "    # if column.dataType\n",
    "\n",
    "    \n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f60ddd",
   "metadata": {},
   "source": [
    "Time to write the dataframe and check Marquez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eab73913",
   "metadata": {},
   "outputs": [],
   "source": [
    "generic_df.write.mode(\"overwrite\").parquet(\"./complex_data_type/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
